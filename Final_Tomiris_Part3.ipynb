{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import matplotlib.image as img\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy import ndimage as nimg\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "data2//Arms//\n",
      "Could not read: data2//Arms//Thumbs.db : cannot identify image file 'data2//Arms//Thumbs.db' - it's ok, skipping.\n",
      "Full dataset tensor: (782, 50, 50)\n",
      "Mean: 0.112784\n",
      "Standard deviation: 0.159394\n",
      "data2//Figure_normal_legs//\n",
      "Could not read: data2//Figure_normal_legs//Thumbs.db : cannot identify image file 'data2//Figure_normal_legs//Thumbs.db' - it's ok, skipping.\n",
      "Full dataset tensor: (621, 50, 50)\n",
      "Mean: 0.0887179\n",
      "Standard deviation: 0.17895\n",
      "data2//FigureWheels//\n",
      "Could not read: data2//FigureWheels//Thumbs.db : cannot identify image file 'data2//FigureWheels//Thumbs.db' - it's ok, skipping.\n",
      "Full dataset tensor: (221, 50, 50)\n",
      "Mean: 0.0751223\n",
      "Standard deviation: 0.18484\n",
      "data2//Head//\n",
      "Could not read: data2//Head//Thumbs.db : cannot identify image file 'data2//Head//Thumbs.db' - it's ok, skipping.\n",
      "Full dataset tensor: (472, 50, 50)\n",
      "Mean: 0.0374206\n",
      "Standard deviation: 0.210797\n"
     ]
    }
   ],
   "source": [
    "im_size =\n",
    "size = im_size,im_size\n",
    "pixel_depth = 255.0 \n",
    "sizes = [782,621,221,472]\n",
    "folders = [\n",
    "    r'Desktop//Tomiris//MVision//data2//Arms//',\n",
    "    r'Desktop//Tomiris//MVisiondata2//Figure_normal_legs//',\n",
    "    r'Desktop//Tomiris//MVisiondata2//FigureWheels//',\n",
    "    r'Desktop//Tomiris//MVisiondata2//Head//',\n",
    "]\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single label.\"\"\"\n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "  print(folder)\n",
    "  num_images = 0\n",
    "  for image in image_files:\n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      img = Image.open(image_file)\n",
    "      newImg = img.resize(size, Image.ANTIALIAS)\n",
    "      image_data = (np.array(newImg).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      num_images = num_images + 1\n",
    "    except IOError as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset\n",
    "\n",
    "X_datasets = list()\n",
    "print(X_datasets)\n",
    "Y_datasets = list()\n",
    "for idx in range(len(folders)):\n",
    "    folder = folders[idx] \n",
    "    X_datasets.append(load_letter(folder, sizes[idx]))\n",
    "    labels = np.zeros((X_datasets[-1].shape[0],len(folders)))\n",
    "    labels[:,idx] = 1\n",
    "    Y_datasets.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Applications/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50)\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2500)              6252500   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1250)              3126250   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2500)              3127500   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 10004     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 12,516,254\n",
      "Trainable params: 12,516,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2500, input_shape=(2500,), activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1250, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2500, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, name=\"output\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1575/1575 [==============================] - 29s 19ms/step - loss: 0.3305 - acc: 0.8756\n",
      "Epoch 2/20\n",
      "1575/1575 [==============================] - 26s 17ms/step - loss: 0.2301 - acc: 0.9130\n",
      "Epoch 3/20\n",
      "1575/1575 [==============================] - 27s 17ms/step - loss: 0.1900 - acc: 0.9322\n",
      "Epoch 4/20\n",
      "1575/1575 [==============================] - 26s 17ms/step - loss: 0.1194 - acc: 0.9548\n",
      "Epoch 5/20\n",
      "1575/1575 [==============================] - 29s 19ms/step - loss: 0.1093 - acc: 0.9592\n",
      "Epoch 6/20\n",
      "1575/1575 [==============================] - 33s 21ms/step - loss: 0.1270 - acc: 0.9679\n",
      "Epoch 7/20\n",
      "1575/1575 [==============================] - 36s 23ms/step - loss: 0.1046 - acc: 0.9656\n",
      "Epoch 8/20\n",
      "1575/1575 [==============================] - 32s 21ms/step - loss: 0.0956 - acc: 0.9708\n",
      "Epoch 9/20\n",
      "1575/1575 [==============================] - 34s 21ms/step - loss: 0.0875 - acc: 0.9765\n",
      "Epoch 10/20\n",
      "1575/1575 [==============================] - 31s 20ms/step - loss: 0.0710 - acc: 0.9763\n",
      "Epoch 11/20\n",
      "1575/1575 [==============================] - 30s 19ms/step - loss: 0.1362 - acc: 0.9767\n",
      "Epoch 12/20\n",
      "1575/1575 [==============================] - 31s 20ms/step - loss: 0.0920 - acc: 0.9773\n",
      "Epoch 13/20\n",
      "1575/1575 [==============================] - 31s 20ms/step - loss: 0.1301 - acc: 0.9792\n",
      "Epoch 14/20\n",
      "1575/1575 [==============================] - 32s 20ms/step - loss: 0.0910 - acc: 0.9849\n",
      "Epoch 15/20\n",
      "1575/1575 [==============================] - 32s 20ms/step - loss: 0.0694 - acc: 0.9854\n",
      "Epoch 16/20\n",
      "1575/1575 [==============================] - 35s 22ms/step - loss: 0.0586 - acc: 0.9917\n",
      "Epoch 17/20\n",
      "1575/1575 [==============================] - 29s 18ms/step - loss: 0.0549 - acc: 0.9927\n",
      "Epoch 18/20\n",
      " 320/1575 [=====>........................] - ETA: 27s - loss: 0.0815 - acc: 0.9820"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Reshape\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import numpy\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.00001, verbose=1),\n",
    "   \n",
    "    ModelCheckpoint(filepath='./weights.net', verbose=1, save_best_only=True),\n",
    "    \n",
    "]\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "input_dim = X_trains[0].shape[0]*X_trains[0].shape[1]\n",
    "print((X_trains[0].shape[0],X_trains[0].shape[1]))\n",
    "print(Y_trains[0].shape[0])\n",
    "model = Sequential()\n",
    "model.add(Reshape((input_dim,), input_shape=(X_trains[0].shape[0],X_trains[0].shape[1])))\n",
    "model.add(Dense(input_dim, input_shape = (input_dim,), init='uniform', activation='relu'))\n",
    "model.add(Dense(int(input_dim/2), init='uniform', activation='relu'))\n",
    "model.add(Dense(int(input_dim), init='uniform', activation='relu'))\n",
    "model.add(Dense(Y_trains[0].shape[0],init='uniform', name=\"output\"))\n",
    "model.add(Activation('softmax', name=\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_trains, \n",
    "          Y_trains, \n",
    "          epochs=20, \n",
    "          batch_size=10, \n",
    "            )\n",
    "\n",
    "results = model.evaluate(X_tests, Y_tests, batch_size=32, verbose=1, sample_weight=None)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
